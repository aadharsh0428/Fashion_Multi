{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Fashion Multi Label Classification .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DOvd0l0UXp3",
        "colab_type": "code",
        "outputId": "a202f3bb-c6ed-4669-82a1-b2046d746a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fosC3cj3lfHR",
        "colab_type": "text"
      },
      "source": [
        "Made a zip file named as Archive 2 which had the test and train data.Combined the train and validation data under a single folder so that it can be manually splitted later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L_5Njz1Wvxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Archive 2.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4JFEYe3vCGe",
        "colab_type": "text"
      },
      "source": [
        "Importing all the necessary header files required for the entire code.\n",
        "After this step the csv containing the image ids and class labels were made note of.Since the image ids were just in terms of integers it needed to be converted to string data type for accessing the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUejAZCSZqqU",
        "colab_type": "code",
        "outputId": "bf364278-783f-4ca9-a83a-b8f6d9075292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from tensorflow.python import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Input, Flatten,Dropout\n",
        "from keras.applications import ResNet50\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "\n",
        "data_train=pd.read_csv(\"/content/drive/My Drive/new_train.csv\")\n",
        "data_train['imageId']=data_train['imageId'].astype(str)\n",
        "data_train['imageId']=data_train['imageId']+\".jpg\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yhQGn_BwDbX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56MJt2WmwKKq",
        "colab_type": "text"
      },
      "source": [
        "We are using the ImageDataGenerator class which will generate batches of tensor image data with real-time data augmentation.The data will be looped over in batches according to the batch size we provide as input.The data is split as 80% for training and 20% for validation.The flow_from_dataframe uses the above mentioned dataframe data_train to read the data from the given directories where the data is stored.The argument class has the value categorical because there are more than 2 classes present here,shuffle allows the data to be accessed in random and the target size of the data is 224 by 224 and all the images are converted to that dimensions.This completes the pre processing and data augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9nDiesxaDLX",
        "colab_type": "code",
        "outputId": "d3be1a93-3e14-4e22-d453-9e0e3f3d1714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "train_generator=datagen.flow_from_dataframe(dataframe=data_train, directory='/tmp/train2/train', x_col=\"imageId\", y_col=\"labelId\", class_mode=\"categorical\",seed=42,subset=\"training\",shuffle=True,target_size=(224,224), batch_size=64)\n",
        "valid_generator=datagen.flow_from_dataframe(dataframe=data_train, directory='/tmp/train2/train', x_col=\"imageId\", y_col=\"labelId\", class_mode=\"categorical\",seed=42,subset=\"validation\",shuffle=True,target_size=(224,224), batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14176 images belonging to 14134 classes.\n",
            "Found 3544 images belonging to 14134 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi0fu9qOzJOv",
        "colab_type": "text"
      },
      "source": [
        "In this phase of the code we define our model.A ResNet50 model is used which provides high accuracies for Image Classification and Segmentation problems.\n",
        "The include_top parameter is false because we are adding a custom based Dense Layer to our model.The weights for the model is as provided by the ImageNet class.Pooling is set as average since our dataset is confined and lot of classes are present we need to consider the mean of all such features which will give us maximized output.Number of units for the first Dense Layer is 128 and activation='relu' mentions we are performing transfer learning usning a rectified linear activation function plus there are 2 advantages one that it converges faster and next it is sparsely activated so for all negative input values it approximates to zero.\n",
        "The final Dense layer consists of 14134 units as the final layer is supposed to have as many units as that of the number of classes present and activation here is sigmoid because it is multi class labelling and predictions are in the form probabilities ranging from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enkvshVF6wTY",
        "colab_type": "code",
        "outputId": "30008933-efa6-420c-a6bd-36d1625d05e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "img = Input(shape = (224, 224, 3))\n",
        "\n",
        "## You can replace DenseNet121 with MobileNet, Xception or ResNet50\n",
        "model = ResNet50(include_top=False,  \n",
        "                    input_tensor=img, \n",
        "                 weights='imagenet',\n",
        "                    input_shape=None, \n",
        "                    pooling='avg')\n",
        "final_layer = model.layers[-1].output\n",
        "\n",
        "dense_layer_1 = Dense(128, activation = 'relu')(final_layer)\n",
        "output_layer = Dense(14134, activation = 'sigmoid')(dense_layer_1)\n",
        "\n",
        "model = Model(input = img, output = output_layer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWiOi0ux2GTm",
        "colab_type": "text"
      },
      "source": [
        "Now the model is ready for compilation.Optimiser is mentioned as adam because it performs better than the exixting stochastic gradient descent and updates weight in an iterative manner at a lower cost of computation.\n",
        "Loss is mentioned as categorical_crossentropy because entropy checks out the homogeneous nature of the information which is an efficient way to analyse the data and categorical since we have more than 2 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgnIa5t87uCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM4xh4Oz4LUN",
        "colab_type": "text"
      },
      "source": [
        "The model is fitted and ready to be trained on the data both training and validation for 10 epochs.\n",
        "Training loss:5.3089e-04.\n",
        "Training accuracy:0.9999\n",
        "Validation loss:0.0012\n",
        "Validation accuracy:0.9996"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkqhG-wf7yNa",
        "colab_type": "code",
        "outputId": "2c123d3c-d73a-4576-eedc-5a9c6628b8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=14176,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=3544,\n",
        "                    epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "14176/14176 [==============================] - 12389s 874ms/step - loss: 5.3089e-04 - acc: 0.9999 - val_loss: 0.0012 - val_acc: 0.9999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a093169b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLWZOryK4xpp",
        "colab_type": "text"
      },
      "source": [
        "The test data's csv file is opened to extract the imageIds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4sMREXy8BVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test=pd.read_csv(\"/content/drive/My Drive/test_2 - Sheet1.csv\")\n",
        "data_test['imageId']=data_test['imageId'].astype(str)\n",
        "data_test['imageId']=data_test['imageId']+\".jpg\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H23HPpG482l",
        "colab_type": "text"
      },
      "source": [
        "The test images are loaded using tqdm library sand are converted into array values after dividing the features by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoqDXHTe1Bp-",
        "colab_type": "code",
        "outputId": "c0652ac1-87be-42d1-f2d6-3aa873909c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "test_image = []\n",
        "for i in tqdm(range(data_test.shape[0])):\n",
        "    img = image.load_img('/tmp/test2/test/'+data_test['imageId'][i], target_size=(224,224,3), grayscale=False)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    test_image.append(img)\n",
        "test = np.array(test_image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6895/6895 [00:33<00:00, 208.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYav_Ib55Lbf",
        "colab_type": "text"
      },
      "source": [
        "Now the model is being predicted with the test data given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IK1PddT4o0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vST6fZBltHbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(test,prediction, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpoOTIiH5ajo",
        "colab_type": "text"
      },
      "source": [
        "The designed model is now evaluated by checking out how it fared with the test data.\n",
        "Test Loss:2.208e-05\n",
        "Test Accuracy:0.987"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wRPSQH4tQfd",
        "colab_type": "code",
        "outputId": "356eb97a-e1f3-445a-9ed5-4624b3c17709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.208984397952011e-05, 0.9874608438372872]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WbXGbTc5vDs",
        "colab_type": "text"
      },
      "source": [
        "The label having the maximum prediction value is chosen and classes have been assigned as such."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObKwUNR-tKYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_classes = prediction.argmax(axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-97ch71NY8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test['labelID']=y_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExKwnc0C5_0p",
        "colab_type": "text"
      },
      "source": [
        "With the classes updated for each image they are updated into the dataframe and the result is converted to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXdbXI4VPN_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test.to_csv('results.csv', header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1VXtkWciGxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('results.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}